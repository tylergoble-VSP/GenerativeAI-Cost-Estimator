{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 07: DGX Spark Performance Monitoring\n",
        "\n",
        "This notebook provides comprehensive performance monitoring for NVIDIA DGX Spark systems.\n",
        "\n",
        "## Features\n",
        "\n",
        "- **SSH Connection Management**: Robust SSH setup with automatic reconnection\n",
        "- **VPN Monitoring**: Tailscale and VPN connection health checks\n",
        "- **GPU Metrics**: Real-time GPU utilization, memory, temperature, and power\n",
        "- **System Metrics**: CPU, RAM, disk I/O, and system load\n",
        "- **Network Metrics**: Bandwidth, latency, and interface statistics\n",
        "- **Real-Time Dashboard**: Live updating visualizations\n",
        "- **Historical Analysis**: Load and analyze past performance data\n",
        "- **Experiment Integration**: Monitor during LLM experiment runs\n",
        "\n",
        "## Usage\n",
        "\n",
        "1. Configure your DGX Spark connection details in Section 1\n",
        "2. Establish SSH connection in Section 2\n",
        "3. Check VPN status in Section 3\n",
        "4. Start monitoring metrics in Section 4-6\n",
        "5. View real-time dashboard in Section 7\n",
        "6. Export data for analysis in Section 8\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Setup and Configuration\n",
        "\n",
        "First, let's import all necessary libraries and configure connection settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary modules\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import Optional, Dict, List, Any\n",
        "\n",
        "# Data manipulation and visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# Add the src directory to Python path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Import our monitoring module\n",
        "from src.dgx_monitoring import (\n",
        "    SSHConnection,\n",
        "    check_vpn_status,\n",
        "    get_gpu_metrics_nvidia_smi,\n",
        "    get_gpu_metrics_nvml,\n",
        "    get_system_metrics,\n",
        "    get_network_metrics,\n",
        "    collect_all_metrics,\n",
        "    export_metrics_to_json,\n",
        "    export_metrics_to_csv\n",
        ")\n",
        "\n",
        "print(\"‚úÖ All modules imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configuration\n",
        "\n",
        "Configure your DGX Spark connection details here. Update these values to match your setup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# DGX SPARK CONNECTION CONFIGURATION\n",
        "# ============================================================================\n",
        "# Update these values to match your DGX Spark setup\n",
        "\n",
        "# SSH Connection Settings\n",
        "DGX_HOSTNAME = \"spark-xxxx.local\"  # Replace with your DGX Spark hostname or IP\n",
        "DGX_USERNAME = \"your_username\"     # Replace with your SSH username\n",
        "DGX_SSH_PORT = 22                  # Default SSH port (usually 22)\n",
        "DGX_SSH_KEY_PATH = None            # Path to SSH private key (optional, e.g., \"~/.ssh/id_rsa\")\n",
        "DGX_SSH_PASSWORD = None            # SSH password (optional, less secure than key)\n",
        "\n",
        "# Monitoring Settings\n",
        "MONITORING_INTERVAL_SECONDS = 5    # How often to collect metrics (in seconds)\n",
        "USE_NVML_FOR_GPU = False           # Use NVML library (local only) vs nvidia-smi\n",
        "ENABLE_REAL_TIME_DASHBOARD = True  # Enable live updating dashboard\n",
        "\n",
        "# Alert Thresholds (for visual indicators)\n",
        "GPU_TEMP_WARNING = 80              # GPU temperature warning threshold (¬∞C)\n",
        "GPU_TEMP_CRITICAL = 90             # GPU temperature critical threshold (¬∞C)\n",
        "MEMORY_WARNING_PCT = 85            # Memory usage warning threshold (%)\n",
        "DISK_WARNING_PCT = 85              # Disk usage warning threshold (%)\n",
        "\n",
        "# Data Storage\n",
        "METRICS_SAVE_DIR = Path(\"notebooks/results/dgx_monitoring\")\n",
        "METRICS_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Configuration loaded!\")\n",
        "print(f\"   Hostname: {DGX_HOSTNAME}\")\n",
        "print(f\"   Username: {DGX_USERNAME}\")\n",
        "print(f\"   Monitoring interval: {MONITORING_INTERVAL_SECONDS}s\")\n",
        "print(f\"   Metrics save directory: {METRICS_SAVE_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: SSH Connection Management\n",
        "\n",
        "Establish and manage SSH connection to DGX Spark with automatic reconnection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize SSH connection object\n",
        "# This creates the connection object but doesn't connect yet\n",
        "ssh_connection = SSHConnection(\n",
        "    hostname=DGX_HOSTNAME,\n",
        "    username=DGX_USERNAME,\n",
        "    key_path=DGX_SSH_KEY_PATH,\n",
        "    password=DGX_SSH_PASSWORD,\n",
        "    port=DGX_SSH_PORT\n",
        ")\n",
        "\n",
        "print(f\"SSH connection object created for {DGX_USERNAME}@{DGX_HOSTNAME}:{DGX_SSH_PORT}\")\n",
        "print(\"Ready to connect...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Establish SSH connection\n",
        "# This will attempt to connect to the DGX Spark system\n",
        "print(f\"Attempting to connect to {DGX_HOSTNAME}...\")\n",
        "\n",
        "connection_successful = ssh_connection.connect(timeout=10)\n",
        "\n",
        "if connection_successful:\n",
        "    print(\"‚úÖ SSH connection established successfully!\")\n",
        "    \n",
        "    # Test the connection by running a simple command\n",
        "    success, stdout, stderr = ssh_connection.execute_command(\"hostname && uptime\")\n",
        "    if success:\n",
        "        print(\"\\nüìä System Information:\")\n",
        "        print(stdout)\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  Connection test failed: {stderr}\")\n",
        "else:\n",
        "    print(\"‚ùå SSH connection failed!\")\n",
        "    print(\"\\nTroubleshooting tips:\")\n",
        "    print(\"  1. Verify hostname/IP is correct\")\n",
        "    print(\"  2. Check if VPN is connected (if required)\")\n",
        "    print(\"  3. Verify SSH key path or password is correct\")\n",
        "    print(\"  4. Check firewall/network settings\")\n",
        "    print(\"  5. Try connecting manually: ssh {}@{}\".format(DGX_USERNAME, DGX_HOSTNAME))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Connection health check function\n",
        "# This function checks if the SSH connection is still alive and can be used periodically\n",
        "\n",
        "def check_ssh_health(ssh: SSHConnection) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Check SSH connection health.\n",
        "    \n",
        "    Returns dictionary with connection status and latency information.\n",
        "    \"\"\"\n",
        "    health = {\n",
        "        \"connected\": False,\n",
        "        \"latency_ms\": None,\n",
        "        \"uptime_seconds\": None,\n",
        "        \"error\": None\n",
        "    }\n",
        "    \n",
        "    if not ssh:\n",
        "        health[\"error\"] = \"SSH connection object not initialized\"\n",
        "        return health\n",
        "    \n",
        "    # Check if connected\n",
        "    health[\"connected\"] = ssh.is_connected()\n",
        "    \n",
        "    if health[\"connected\"]:\n",
        "        # Measure latency by running a simple command\n",
        "        start_time = time.time()\n",
        "        success, stdout, stderr = ssh.execute_command(\"echo 'ping'\", timeout=5)\n",
        "        end_time = time.time()\n",
        "        \n",
        "        if success:\n",
        "            health[\"latency_ms\"] = (end_time - start_time) * 1000\n",
        "            \n",
        "            # Get system uptime\n",
        "            success, stdout, stderr = ssh.execute_command(\"cat /proc/uptime\", timeout=5)\n",
        "            if success:\n",
        "                try:\n",
        "                    uptime_seconds = float(stdout.split()[0])\n",
        "                    health[\"uptime_seconds\"] = uptime_seconds\n",
        "                except:\n",
        "                    pass\n",
        "        else:\n",
        "            health[\"error\"] = stderr\n",
        "            health[\"connected\"] = False\n",
        "    \n",
        "    return health\n",
        "\n",
        "# Test connection health\n",
        "if ssh_connection.is_connected():\n",
        "    health_status = check_ssh_health(ssh_connection)\n",
        "    print(\"üì° SSH Connection Health:\")\n",
        "    print(f\"   Status: {'‚úÖ Connected' if health_status['connected'] else '‚ùå Disconnected'}\")\n",
        "    if health_status['latency_ms']:\n",
        "        print(f\"   Latency: {health_status['latency_ms']:.2f} ms\")\n",
        "    if health_status['uptime_seconds']:\n",
        "        uptime_days = health_status['uptime_seconds'] / 86400\n",
        "        print(f\"   System Uptime: {uptime_days:.1f} days\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  SSH connection not established. Run the connection cell above first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: VPN Connection Monitoring\n",
        "\n",
        "Check VPN connection status (Tailscale or other VPN services).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check VPN status\n",
        "# This will check for Tailscale or other VPN services\n",
        "# If SSH is connected, it checks on the remote host; otherwise checks locally\n",
        "\n",
        "vpn_status = check_vpn_status(ssh_connection if ssh_connection.is_connected() else None)\n",
        "\n",
        "print(\"üîí VPN Connection Status:\")\n",
        "print(f\"   VPN Available: {'‚úÖ Yes' if vpn_status['vpn_available'] else '‚ùå No'}\")\n",
        "if vpn_status['vpn_type']:\n",
        "    print(f\"   VPN Type: {vpn_status['vpn_type']}\")\n",
        "print(f\"   Connected: {'‚úÖ Yes' if vpn_status['connected'] else '‚ùå No'}\")\n",
        "print(f\"   Status: {vpn_status['status_message']}\")\n",
        "\n",
        "# Display VPN status indicator\n",
        "if vpn_status['connected']:\n",
        "    print(\"\\n‚úÖ VPN is connected - you should be able to access DGX Spark\")\n",
        "elif vpn_status['vpn_available']:\n",
        "    print(\"\\n‚ö†Ô∏è  VPN is installed but not connected\")\n",
        "    print(\"   You may need to connect to VPN before establishing SSH connection\")\n",
        "else:\n",
        "    print(\"\\n‚ÑπÔ∏è  VPN not detected or not required for your setup\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: GPU Performance Metrics\n",
        "\n",
        "Monitor GPU utilization, memory, temperature, and power consumption.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get GPU metrics\n",
        "# This function collects GPU information using nvidia-smi (works both locally and remotely)\n",
        "# For local monitoring with NVML, set USE_NVML_FOR_GPU = True in configuration\n",
        "\n",
        "ssh = ssh_connection if ssh_connection.is_connected() else None\n",
        "\n",
        "if USE_NVML_FOR_GPU and not ssh:\n",
        "    # Use NVML for local monitoring (more efficient)\n",
        "    gpu_metrics = get_gpu_metrics_nvml(ssh)\n",
        "    method = \"NVML\"\n",
        "else:\n",
        "    # Use nvidia-smi (works both locally and remotely)\n",
        "    gpu_metrics = get_gpu_metrics_nvidia_smi(ssh)\n",
        "    method = \"nvidia-smi\"\n",
        "\n",
        "print(f\"üìä GPU Metrics (via {method}):\")\n",
        "print(f\"   Found {len(gpu_metrics)} GPU(s)\\n\")\n",
        "\n",
        "if gpu_metrics:\n",
        "    for gpu in gpu_metrics:\n",
        "        print(f\"GPU {gpu['index']}: {gpu['name']}\")\n",
        "        print(f\"   Utilization: {gpu['utilization_gpu']:.1f}%\")\n",
        "        print(f\"   Memory: {gpu['memory_used_mb']:.0f} MB / {gpu['memory_total_mb']:.0f} MB ({gpu['memory_used_pct']:.1f}%)\")\n",
        "        print(f\"   Temperature: {gpu['temperature_c']:.1f}¬∞C\")\n",
        "        print(f\"   Power: {gpu['power_draw_w']:.1f}W / {gpu['power_limit_w']:.1f}W\")\n",
        "        \n",
        "        # Add warning indicators\n",
        "        if gpu['temperature_c'] >= GPU_TEMP_CRITICAL:\n",
        "            print(f\"   ‚ö†Ô∏è  CRITICAL: Temperature is very high!\")\n",
        "        elif gpu['temperature_c'] >= GPU_TEMP_WARNING:\n",
        "            print(f\"   ‚ö†Ô∏è  WARNING: Temperature is high\")\n",
        "        \n",
        "        print()\n",
        "else:\n",
        "    print(\"‚ùå No GPU metrics collected. Possible issues:\")\n",
        "    print(\"   - No GPUs available\")\n",
        "    print(\"   - nvidia-smi not available on target system\")\n",
        "    print(\"   - Permission issues\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: System Metrics (CPU, RAM, Disk)\n",
        "\n",
        "Monitor CPU utilization, memory usage, disk I/O, and system load.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get system metrics\n",
        "# This collects CPU, RAM, disk, and load information\n",
        "# Note: For remote monitoring via SSH, some metrics may be limited\n",
        "\n",
        "system_metrics = get_system_metrics(ssh)\n",
        "\n",
        "print(\"üíª System Metrics:\")\n",
        "\n",
        "if system_metrics:\n",
        "    # CPU Information\n",
        "    if 'cpu_percent' in system_metrics:\n",
        "        print(f\"\\nüñ•Ô∏è  CPU:\")\n",
        "        print(f\"   Overall Utilization: {system_metrics['cpu_percent']:.1f}%\")\n",
        "        print(f\"   CPU Cores: {system_metrics.get('cpu_count', 'N/A')}\")\n",
        "        if 'cpu_per_core' in system_metrics:\n",
        "            per_core = system_metrics['cpu_per_core']\n",
        "            print(f\"   Per-Core Utilization: {', '.join([f'{c:.1f}%' for c in per_core])}\")\n",
        "        if 'load_avg_1min' in system_metrics:\n",
        "            print(f\"   Load Average (1min): {system_metrics['load_avg_1min']:.2f}\")\n",
        "    \n",
        "    # Memory Information\n",
        "    if 'memory_total_gb' in system_metrics:\n",
        "        print(f\"\\nüß† Memory:\")\n",
        "        print(f\"   Total: {system_metrics['memory_total_gb']:.2f} GB\")\n",
        "        print(f\"   Used: {system_metrics['memory_used_gb']:.2f} GB ({system_metrics['memory_percent']:.1f}%)\")\n",
        "        print(f\"   Available: {system_metrics.get('memory_available_gb', 0):.2f} GB\")\n",
        "        \n",
        "        if system_metrics['memory_percent'] >= MEMORY_WARNING_PCT:\n",
        "            print(f\"   ‚ö†Ô∏è  WARNING: Memory usage is high!\")\n",
        "        \n",
        "        if 'swap_total_gb' in system_metrics and system_metrics['swap_total_gb'] > 0:\n",
        "            print(f\"   Swap: {system_metrics['swap_used_gb']:.2f} GB / {system_metrics['swap_total_gb']:.2f} GB ({system_metrics['swap_percent']:.1f}%)\")\n",
        "    \n",
        "    # Disk Information\n",
        "    if 'disk_usage' in system_metrics:\n",
        "        print(f\"\\nüíæ Disk Usage:\")\n",
        "        for mountpoint, usage in system_metrics['disk_usage'].items():\n",
        "            print(f\"   {mountpoint}:\")\n",
        "            print(f\"      Used: {usage['used_gb']:.2f} GB / {usage['total_gb']:.2f} GB ({usage['percent']:.1f}%)\")\n",
        "            print(f\"      Free: {usage['free_gb']:.2f} GB\")\n",
        "            \n",
        "            if usage['percent'] >= DISK_WARNING_PCT:\n",
        "                print(f\"      ‚ö†Ô∏è  WARNING: Disk usage is high!\")\n",
        "        \n",
        "        if 'disk_read_mb' in system_metrics:\n",
        "            print(f\"\\n   Disk I/O:\")\n",
        "            print(f\"      Read: {system_metrics['disk_read_mb']:.2f} MB\")\n",
        "            print(f\"      Write: {system_metrics['disk_write_mb']:.2f} MB\")\n",
        "else:\n",
        "    print(\"‚ùå Could not collect system metrics\")\n",
        "    print(\"   This may be normal if monitoring remotely via SSH\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6: Network Performance\n",
        "\n",
        "Monitor network bandwidth, latency, and interface statistics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get network metrics\n",
        "network_metrics = get_network_metrics(ssh)\n",
        "\n",
        "print(\"üåê Network Metrics:\")\n",
        "\n",
        "if network_metrics:\n",
        "    if 'bytes_sent_mb' in network_metrics:\n",
        "        print(f\"\\nüì§ Network I/O:\")\n",
        "        print(f\"   Bytes Sent: {network_metrics['bytes_sent_mb']:.2f} MB\")\n",
        "        print(f\"   Bytes Received: {network_metrics['bytes_recv_mb']:.2f} MB\")\n",
        "        print(f\"   Packets Sent: {network_metrics.get('packets_sent', 0):,}\")\n",
        "        print(f\"   Packets Received: {network_metrics.get('packets_recv', 0):,}\")\n",
        "    \n",
        "    if 'connections' in network_metrics:\n",
        "        print(f\"   Active Connections: {network_metrics['connections']}\")\n",
        "    \n",
        "    if 'interfaces' in network_metrics:\n",
        "        print(f\"\\nüîå Network Interfaces:\")\n",
        "        for interface, stats in network_metrics['interfaces'].items():\n",
        "            status = \"‚úÖ UP\" if stats.get('isup', False) else \"‚ùå DOWN\"\n",
        "            print(f\"   {interface}: {status}\")\n",
        "            if stats.get('speed_mbps', 0) > 0:\n",
        "                print(f\"      Speed: {stats['speed_mbps']} Mbps\")\n",
        "            if stats.get('mtu'):\n",
        "                print(f\"      MTU: {stats['mtu']}\")\n",
        "else:\n",
        "    print(\"‚ùå Could not collect network metrics\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 7: Real-Time Monitoring Dashboard\n",
        "\n",
        "Live updating dashboard showing all metrics in real-time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize data storage for real-time monitoring\n",
        "# This will store metrics over time for plotting\n",
        "\n",
        "monitoring_data = {\n",
        "    \"timestamps\": [],\n",
        "    \"gpu_data\": [],  # List of GPU metric dictionaries\n",
        "    \"system_data\": [],\n",
        "    \"network_data\": []\n",
        "}\n",
        "\n",
        "print(\"‚úÖ Monitoring data storage initialized\")\n",
        "print(f\"   Ready to collect metrics every {MONITORING_INTERVAL_SECONDS} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to collect one sample of all metrics\n",
        "def collect_metrics_sample():\n",
        "    \"\"\"\n",
        "    Collect one sample of all metrics and store in monitoring_data.\n",
        "    \"\"\"\n",
        "    ssh = ssh_connection if ssh_connection.is_connected() else None\n",
        "    \n",
        "    # Collect all metrics at once\n",
        "    all_metrics = collect_all_metrics(ssh, use_nvml=USE_NVML_FOR_GPU)\n",
        "    \n",
        "    # Store in our data structure\n",
        "    timestamp = datetime.now()\n",
        "    monitoring_data[\"timestamps\"].append(timestamp)\n",
        "    monitoring_data[\"gpu_data\"].append(all_metrics[\"gpu_metrics\"])\n",
        "    monitoring_data[\"system_data\"].append(all_metrics[\"system_metrics\"])\n",
        "    monitoring_data[\"network_data\"].append(all_metrics[\"network_metrics\"])\n",
        "    \n",
        "    return all_metrics\n",
        "\n",
        "# Test collection\n",
        "print(\"Collecting initial metrics sample...\")\n",
        "sample = collect_metrics_sample()\n",
        "print(f\"‚úÖ Collected metrics at {sample['timestamp_readable']}\")\n",
        "print(f\"   GPUs: {len(sample['gpu_metrics'])}\")\n",
        "print(f\"   SSH Connected: {sample['ssh_connected']}\")\n",
        "print(f\"   VPN Connected: {sample['vpn_status']['connected']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create real-time monitoring dashboard\n",
        "# This creates live-updating plots showing key metrics over time\n",
        "\n",
        "if ENABLE_REAL_TIME_DASHBOARD:\n",
        "    # Set up the figure with subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('DGX Spark Performance Monitoring Dashboard', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # Flatten axes for easier indexing\n",
        "    ax1, ax2, ax3, ax4 = axes.flatten()\n",
        "    \n",
        "    # Plot 1: GPU Utilization\n",
        "    ax1.set_title('GPU Utilization (%)', fontweight='bold')\n",
        "    ax1.set_xlabel('Time')\n",
        "    ax1.set_ylabel('Utilization (%)')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.set_ylim(0, 100)\n",
        "    \n",
        "    # Plot 2: GPU Memory Usage\n",
        "    ax2.set_title('GPU Memory Usage (%)', fontweight='bold')\n",
        "    ax2.set_xlabel('Time')\n",
        "    ax2.set_ylabel('Memory Usage (%)')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.set_ylim(0, 100)\n",
        "    \n",
        "    # Plot 3: GPU Temperature\n",
        "    ax3.set_title('GPU Temperature (¬∞C)', fontweight='bold')\n",
        "    ax3.set_xlabel('Time')\n",
        "    ax3.set_ylabel('Temperature (¬∞C)')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    ax3.axhline(y=GPU_TEMP_WARNING, color='orange', linestyle='--', label=f'Warning ({GPU_TEMP_WARNING}¬∞C)')\n",
        "    ax3.axhline(y=GPU_TEMP_CRITICAL, color='red', linestyle='--', label=f'Critical ({GPU_TEMP_CRITICAL}¬∞C)')\n",
        "    ax3.legend()\n",
        "    \n",
        "    # Plot 4: System CPU and Memory\n",
        "    ax4.set_title('System CPU and Memory Usage (%)', fontweight='bold')\n",
        "    ax4.set_xlabel('Time')\n",
        "    ax4.set_ylabel('Usage (%)')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    ax4.set_ylim(0, 100)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    def update_dashboard(frame):\n",
        "        \"\"\"Update function for animation.\"\"\"\n",
        "        # Collect new metrics\n",
        "        collect_metrics_sample()\n",
        "        \n",
        "        if len(monitoring_data[\"timestamps\"]) == 0:\n",
        "            return\n",
        "        \n",
        "        # Clear and replot\n",
        "        ax1.clear()\n",
        "        ax2.clear()\n",
        "        ax3.clear()\n",
        "        ax4.clear()\n",
        "        \n",
        "        # Get recent data (last 50 samples or all if less)\n",
        "        n_samples = min(50, len(monitoring_data[\"timestamps\"]))\n",
        "        recent_times = monitoring_data[\"timestamps\"][-n_samples:]\n",
        "        recent_gpu = monitoring_data[\"gpu_data\"][-n_samples:]\n",
        "        recent_system = monitoring_data[\"system_data\"][-n_samples:]\n",
        "        \n",
        "        # Plot GPU Utilization\n",
        "        for gpu_idx in range(len(recent_gpu[0]) if recent_gpu else 0):\n",
        "            utilizations = [gpu[gpu_idx]['utilization_gpu'] for gpu in recent_gpu if len(gpu) > gpu_idx]\n",
        "            if utilizations:\n",
        "                ax1.plot(recent_times[:len(utilizations)], utilizations, label=f'GPU {gpu_idx}', marker='o', markersize=3)\n",
        "        ax1.set_title('GPU Utilization (%)', fontweight='bold')\n",
        "        ax1.set_xlabel('Time')\n",
        "        ax1.set_ylabel('Utilization (%)')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_ylim(0, 100)\n",
        "        ax1.legend()\n",
        "        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
        "        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
        "        \n",
        "        # Plot GPU Memory\n",
        "        for gpu_idx in range(len(recent_gpu[0]) if recent_gpu else 0):\n",
        "            memory_pcts = [gpu[gpu_idx]['memory_used_pct'] for gpu in recent_gpu if len(gpu) > gpu_idx]\n",
        "            if memory_pcts:\n",
        "                ax2.plot(recent_times[:len(memory_pcts)], memory_pcts, label=f'GPU {gpu_idx}', marker='o', markersize=3)\n",
        "        ax2.set_title('GPU Memory Usage (%)', fontweight='bold')\n",
        "        ax2.set_xlabel('Time')\n",
        "        ax2.set_ylabel('Memory Usage (%)')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.set_ylim(0, 100)\n",
        "        ax2.legend()\n",
        "        ax2.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
        "        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)\n",
        "        \n",
        "        # Plot GPU Temperature\n",
        "        for gpu_idx in range(len(recent_gpu[0]) if recent_gpu else 0):\n",
        "            temps = [gpu[gpu_idx]['temperature_c'] for gpu in recent_gpu if len(gpu) > gpu_idx]\n",
        "            if temps:\n",
        "                ax3.plot(recent_times[:len(temps)], temps, label=f'GPU {gpu_idx}', marker='o', markersize=3)\n",
        "        ax3.set_title('GPU Temperature (¬∞C)', fontweight='bold')\n",
        "        ax3.set_xlabel('Time')\n",
        "        ax3.set_ylabel('Temperature (¬∞C)')\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "        ax3.axhline(y=GPU_TEMP_WARNING, color='orange', linestyle='--', label=f'Warning ({GPU_TEMP_WARNING}¬∞C)')\n",
        "        ax3.axhline(y=GPU_TEMP_CRITICAL, color='red', linestyle='--', label=f'Critical ({GPU_TEMP_CRITICAL}¬∞C)')\n",
        "        ax3.legend()\n",
        "        ax3.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
        "        plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45)\n",
        "        \n",
        "        # Plot System CPU and Memory\n",
        "        cpu_pcts = [sys.get('cpu_percent', 0) for sys in recent_system if sys]\n",
        "        mem_pcts = [sys.get('memory_percent', 0) for sys in recent_system if sys]\n",
        "        if cpu_pcts:\n",
        "            ax4.plot(recent_times[:len(cpu_pcts)], cpu_pcts, label='CPU %', marker='o', markersize=3)\n",
        "        if mem_pcts:\n",
        "            ax4.plot(recent_times[:len(mem_pcts)], mem_pcts, label='Memory %', marker='s', markersize=3)\n",
        "        ax4.set_title('System CPU and Memory Usage (%)', fontweight='bold')\n",
        "        ax4.set_xlabel('Time')\n",
        "        ax4.set_ylabel('Usage (%)')\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "        ax4.set_ylim(0, 100)\n",
        "        ax4.legend()\n",
        "        ax4.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
        "        plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "    \n",
        "    print(\"‚úÖ Dashboard created!\")\n",
        "    print(\"   The dashboard will update automatically when you run the animation cell below.\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è  Real-time dashboard is disabled in configuration\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start real-time monitoring animation\n",
        "# This will continuously collect metrics and update the dashboard\n",
        "# Press the stop button in Jupyter to stop monitoring\n",
        "\n",
        "if ENABLE_REAL_TIME_DASHBOARD and len(monitoring_data[\"timestamps\"]) > 0:\n",
        "    # Create animation that updates every MONITORING_INTERVAL_SECONDS\n",
        "    # interval is in milliseconds\n",
        "    interval_ms = MONITORING_INTERVAL_SECONDS * 1000\n",
        "    \n",
        "    print(f\"üîÑ Starting real-time monitoring...\")\n",
        "    print(f\"   Update interval: {MONITORING_INTERVAL_SECONDS} seconds\")\n",
        "    print(f\"   Press the stop button (‚ñ†) to stop monitoring\")\n",
        "    \n",
        "    # Create animation\n",
        "    # Note: This will run until stopped manually\n",
        "    ani = FuncAnimation(fig, update_dashboard, interval=interval_ms, blit=False, cache_frame_data=False)\n",
        "    \n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è  Dashboard not enabled or no data collected yet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 8: Data Collection and Storage\n",
        "\n",
        "Export collected metrics to files for historical analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect metrics for a specified duration\n",
        "# This function collects metrics over time and stores them\n",
        "\n",
        "def collect_metrics_duration(duration_seconds: int, interval_seconds: int = None):\n",
        "    \"\"\"\n",
        "    Collect metrics for a specified duration.\n",
        "    \n",
        "    Args:\n",
        "        duration_seconds: How long to collect metrics (in seconds)\n",
        "        interval_seconds: How often to collect (defaults to MONITORING_INTERVAL_SECONDS)\n",
        "    \"\"\"\n",
        "    if interval_seconds is None:\n",
        "        interval_seconds = MONITORING_INTERVAL_SECONDS\n",
        "    \n",
        "    print(f\"üìä Collecting metrics for {duration_seconds} seconds...\")\n",
        "    print(f\"   Interval: {interval_seconds} seconds\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    samples_collected = 0\n",
        "    \n",
        "    while time.time() - start_time < duration_seconds:\n",
        "        collect_metrics_sample()\n",
        "        samples_collected += 1\n",
        "        \n",
        "        elapsed = time.time() - start_time\n",
        "        remaining = duration_seconds - elapsed\n",
        "        \n",
        "        if remaining > 0:\n",
        "            print(f\"   Collected {samples_collected} samples, {remaining:.1f}s remaining...\", end='\\r')\n",
        "            time.sleep(min(interval_seconds, remaining))\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    print(f\"\\n‚úÖ Collection complete! Collected {samples_collected} samples\")\n",
        "\n",
        "# Example: Collect metrics for 30 seconds\n",
        "# Uncomment the line below to run\n",
        "# collect_metrics_duration(30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare collected metrics for export\n",
        "# Convert our monitoring_data structure to the format expected by export functions\n",
        "\n",
        "def prepare_metrics_for_export() -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Convert monitoring_data to list of metric dictionaries for export.\n",
        "    \"\"\"\n",
        "    exported_metrics = []\n",
        "    \n",
        "    for i, timestamp in enumerate(monitoring_data[\"timestamps\"]):\n",
        "        metric = {\n",
        "            \"timestamp\": timestamp.isoformat(),\n",
        "            \"timestamp_readable\": timestamp.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            \"gpu_metrics\": monitoring_data[\"gpu_data\"][i] if i < len(monitoring_data[\"gpu_data\"]) else [],\n",
        "            \"system_metrics\": monitoring_data[\"system_data\"][i] if i < len(monitoring_data[\"system_data\"]) else [],\n",
        "            \"network_metrics\": monitoring_data[\"network_data\"][i] if i < len(monitoring_data[\"network_data\"]) else []\n",
        "        }\n",
        "        exported_metrics.append(metric)\n",
        "    \n",
        "    return exported_metrics\n",
        "\n",
        "# Export to JSON\n",
        "if len(monitoring_data[\"timestamps\"]) > 0:\n",
        "    metrics_to_export = prepare_metrics_for_export()\n",
        "    \n",
        "    # Generate filename with timestamp\n",
        "    timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    json_filepath = METRICS_SAVE_DIR / f\"dgx_metrics_{timestamp_str}.json\"\n",
        "    \n",
        "    export_metrics_to_json(metrics_to_export, json_filepath)\n",
        "    print(f\"‚úÖ Metrics exported to JSON: {json_filepath}\")\n",
        "    print(f\"   Total samples: {len(metrics_to_export)}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No metrics collected yet. Run monitoring cells above first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export to CSV\n",
        "if len(monitoring_data[\"timestamps\"]) > 0:\n",
        "    metrics_to_export = prepare_metrics_for_export()\n",
        "    \n",
        "    # Generate filename with timestamp\n",
        "    timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    csv_filepath = METRICS_SAVE_DIR / f\"dgx_metrics_{timestamp_str}.csv\"\n",
        "    \n",
        "    export_metrics_to_csv(metrics_to_export, csv_filepath)\n",
        "    print(f\"‚úÖ Metrics exported to CSV: {csv_filepath}\")\n",
        "    print(f\"   Total samples: {len(metrics_to_export)}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No metrics collected yet. Run monitoring cells above first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 9: Integration with LLM Experiments\n",
        "\n",
        "Monitor DGX Spark performance during LLM experiment runs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to monitor during experiment execution\n",
        "# This can be called from other notebooks or run in parallel\n",
        "\n",
        "def monitor_during_experiment(experiment_name: str, duration_seconds: int = None):\n",
        "    \"\"\"\n",
        "    Monitor DGX Spark during an experiment run.\n",
        "    \n",
        "    Args:\n",
        "        experiment_name: Name/identifier for this experiment\n",
        "        duration_seconds: How long to monitor (None = until stopped manually)\n",
        "    \"\"\"\n",
        "    print(f\"üî¨ Starting monitoring for experiment: {experiment_name}\")\n",
        "    \n",
        "    # Create experiment-specific data storage\n",
        "    experiment_data = {\n",
        "        \"experiment_name\": experiment_name,\n",
        "        \"start_time\": datetime.now(),\n",
        "        \"timestamps\": [],\n",
        "        \"gpu_data\": [],\n",
        "        \"system_data\": [],\n",
        "        \"network_data\": []\n",
        "    }\n",
        "    \n",
        "    start_time = time.time()\n",
        "    samples_collected = 0\n",
        "    \n",
        "    try:\n",
        "        while duration_seconds is None or (time.time() - start_time) < duration_seconds:\n",
        "            # Collect metrics\n",
        "            ssh = ssh_connection if ssh_connection.is_connected() else None\n",
        "            all_metrics = collect_all_metrics(ssh, use_nvml=USE_NVML_FOR_GPU)\n",
        "            \n",
        "            # Store in experiment data\n",
        "            timestamp = datetime.now()\n",
        "            experiment_data[\"timestamps\"].append(timestamp)\n",
        "            experiment_data[\"gpu_data\"].append(all_metrics[\"gpu_metrics\"])\n",
        "            experiment_data[\"system_data\"].append(all_metrics[\"system_metrics\"])\n",
        "            experiment_data[\"network_data\"].append(all_metrics[\"network_metrics\"])\n",
        "            \n",
        "            samples_collected += 1\n",
        "            \n",
        "            # Print status\n",
        "            elapsed = time.time() - start_time\n",
        "            if duration_seconds:\n",
        "                remaining = duration_seconds - elapsed\n",
        "                print(f\"   [{elapsed:.0f}s] Collected {samples_collected} samples, {remaining:.1f}s remaining...\", end='\\r')\n",
        "            else:\n",
        "                print(f\"   [{elapsed:.0f}s] Collected {samples_collected} samples...\", end='\\r')\n",
        "            \n",
        "            time.sleep(MONITORING_INTERVAL_SECONDS)\n",
        "    \n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n‚ö†Ô∏è  Monitoring stopped by user\")\n",
        "    \n",
        "    experiment_data[\"end_time\"] = datetime.now()\n",
        "    experiment_data[\"duration_seconds\"] = (experiment_data[\"end_time\"] - experiment_data[\"start_time\"]).total_seconds()\n",
        "    \n",
        "    print(f\"\\n‚úÖ Monitoring complete for experiment: {experiment_name}\")\n",
        "    print(f\"   Duration: {experiment_data['duration_seconds']:.1f} seconds\")\n",
        "    print(f\"   Samples collected: {samples_collected}\")\n",
        "    \n",
        "    # Export experiment data\n",
        "    timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    experiment_filepath = METRICS_SAVE_DIR / f\"experiment_{experiment_name}_{timestamp_str}.json\"\n",
        "    \n",
        "    export_data = {\n",
        "        \"experiment_info\": {\n",
        "            \"name\": experiment_name,\n",
        "            \"start_time\": experiment_data[\"start_time\"].isoformat(),\n",
        "            \"end_time\": experiment_data[\"end_time\"].isoformat(),\n",
        "            \"duration_seconds\": experiment_data[\"duration_seconds\"]\n",
        "        },\n",
        "        \"metrics\": prepare_metrics_for_export()\n",
        "    }\n",
        "    \n",
        "    with open(experiment_filepath, 'w') as f:\n",
        "        json.dump(export_data, f, indent=2)\n",
        "    \n",
        "    print(f\"   Data exported to: {experiment_filepath}\")\n",
        "    \n",
        "    return experiment_data\n",
        "\n",
        "# Example usage:\n",
        "# experiment_monitoring = monitor_during_experiment(\"nolh_experiment_1\", duration_seconds=300)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 10: Historical Analysis\n",
        "\n",
        "Load and analyze past performance data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to load historical metrics from JSON file\n",
        "def load_historical_metrics(filepath: Path) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Load historical metrics from a JSON export file.\n",
        "    \n",
        "    Args:\n",
        "        filepath: Path to JSON file\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with loaded metrics\n",
        "    \"\"\"\n",
        "    if isinstance(filepath, Path):\n",
        "        filepath = str(filepath)\n",
        "    \n",
        "    with open(filepath, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    return data\n",
        "\n",
        "# List available metric files\n",
        "print(\"üìÅ Available metric files:\")\n",
        "metric_files = list(METRICS_SAVE_DIR.glob(\"dgx_metrics_*.json\"))\n",
        "experiment_files = list(METRICS_SAVE_DIR.glob(\"experiment_*.json\"))\n",
        "\n",
        "if metric_files:\n",
        "    print(\"\\n   General monitoring files:\")\n",
        "    for f in sorted(metric_files)[-5:]:  # Show last 5\n",
        "        print(f\"      - {f.name}\")\n",
        "else:\n",
        "    print(\"   No general monitoring files found\")\n",
        "\n",
        "if experiment_files:\n",
        "    print(\"\\n   Experiment files:\")\n",
        "    for f in sorted(experiment_files)[-5:]:  # Show last 5\n",
        "        print(f\"      - {f.name}\")\n",
        "else:\n",
        "    print(\"   No experiment files found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and visualize historical data\n",
        "# Replace the filepath with an actual file from the list above\n",
        "\n",
        "# Example: Load a specific file\n",
        "# Uncomment and modify the path below to load a specific file\n",
        "# historical_file = METRICS_SAVE_DIR / \"dgx_metrics_20240115_143022.json\"\n",
        "# historical_data = load_historical_metrics(historical_file)\n",
        "\n",
        "# if historical_data:\n",
        "#     print(f\"‚úÖ Loaded historical data:\")\n",
        "#     print(f\"   Export timestamp: {historical_data.get('export_timestamp_readable', 'N/A')}\")\n",
        "#     print(f\"   Number of samples: {historical_data.get('num_samples', 0)}\")\n",
        "#     \n",
        "#     # Extract GPU utilization over time\n",
        "#     metrics = historical_data.get('metrics', [])\n",
        "#     if metrics:\n",
        "#         # Create visualization\n",
        "#         fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "#         fig.suptitle('Historical Performance Analysis', fontsize=16, fontweight='bold')\n",
        "#         ax1, ax2, ax3, ax4 = axes.flatten()\n",
        "#         \n",
        "#         # Extract timestamps and GPU data\n",
        "#         timestamps = [datetime.fromisoformat(m['timestamp']) for m in metrics]\n",
        "#         \n",
        "#         # Plot GPU utilization\n",
        "#         for gpu_idx in range(len(metrics[0].get('gpu_metrics', []))):\n",
        "#             utilizations = [m['gpu_metrics'][gpu_idx]['utilization_gpu'] \n",
        "#                           for m in metrics if len(m.get('gpu_metrics', [])) > gpu_idx]\n",
        "#             if utilizations:\n",
        "#                 ax1.plot(timestamps[:len(utilizations)], utilizations, label=f'GPU {gpu_idx}')\n",
        "#         ax1.set_title('GPU Utilization Over Time')\n",
        "#         ax1.set_xlabel('Time')\n",
        "#         ax1.set_ylabel('Utilization (%)')\n",
        "#         ax1.legend()\n",
        "#         ax1.grid(True, alpha=0.3)\n",
        "#         \n",
        "#         # Similar plots for memory, temperature, etc.\n",
        "#         # ... (add more visualizations as needed)\n",
        "#         \n",
        "#         plt.tight_layout()\n",
        "#         plt.show()\n",
        "# else:\n",
        "#     print(\"‚ö†Ô∏è  No historical data file specified or file not found\")\n",
        "\n",
        "print(\"‚ÑπÔ∏è  Uncomment the code above and specify a file path to load historical data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Troubleshooting and Error Handling\n",
        "\n",
        "Common issues and solutions for DGX Spark monitoring.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive connection health check\n",
        "# Run this if you're experiencing connection issues\n",
        "\n",
        "def comprehensive_health_check():\n",
        "    \"\"\"\n",
        "    Perform comprehensive health check of all connections and services.\n",
        "    \"\"\"\n",
        "    print(\"üîç Comprehensive Health Check\\n\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # 1. SSH Connection\n",
        "    print(\"\\n1. SSH Connection:\")\n",
        "    if ssh_connection:\n",
        "        if ssh_connection.is_connected():\n",
        "            print(\"   ‚úÖ SSH connection is active\")\n",
        "            health = check_ssh_health(ssh_connection)\n",
        "            if health['latency_ms']:\n",
        "                print(f\"   üìä Latency: {health['latency_ms']:.2f} ms\")\n",
        "        else:\n",
        "            print(\"   ‚ùå SSH connection is not active\")\n",
        "            print(\"   üí° Try running the SSH connection cell again\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è  SSH connection object not initialized\")\n",
        "    \n",
        "    # 2. VPN Status\n",
        "    print(\"\\n2. VPN Status:\")\n",
        "    vpn = check_vpn_status(ssh_connection if ssh_connection and ssh_connection.is_connected() else None)\n",
        "    if vpn['connected']:\n",
        "        print(f\"   ‚úÖ VPN connected ({vpn['vpn_type']})\")\n",
        "    elif vpn['vpn_available']:\n",
        "        print(f\"   ‚ö†Ô∏è  VPN available but not connected ({vpn['vpn_type']})\")\n",
        "    else:\n",
        "        print(\"   ‚ÑπÔ∏è  VPN not detected (may not be required)\")\n",
        "    \n",
        "    # 3. GPU Availability\n",
        "    print(\"\\n3. GPU Availability:\")\n",
        "    ssh = ssh_connection if ssh_connection and ssh_connection.is_connected() else None\n",
        "    gpus = get_gpu_metrics_nvidia_smi(ssh)\n",
        "    if gpus:\n",
        "        print(f\"   ‚úÖ Found {len(gpus)} GPU(s)\")\n",
        "        for gpu in gpus:\n",
        "            print(f\"      - GPU {gpu['index']}: {gpu['name']}\")\n",
        "    else:\n",
        "        print(\"   ‚ùå No GPUs detected\")\n",
        "        print(\"   üí° Check if nvidia-smi is available on target system\")\n",
        "    \n",
        "    # 4. System Metrics\n",
        "    print(\"\\n4. System Metrics:\")\n",
        "    system = get_system_metrics(ssh)\n",
        "    if system:\n",
        "        print(\"   ‚úÖ System metrics available\")\n",
        "        if 'cpu_count' in system:\n",
        "            print(f\"      CPU Cores: {system['cpu_count']}\")\n",
        "        if 'memory_total_gb' in system:\n",
        "            print(f\"      Total Memory: {system['memory_total_gb']:.2f} GB\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è  System metrics not available\")\n",
        "        print(\"   üí° This may be normal for remote monitoring\")\n",
        "    \n",
        "    # 5. Data Collection\n",
        "    print(\"\\n5. Data Collection:\")\n",
        "    if len(monitoring_data[\"timestamps\"]) > 0:\n",
        "        print(f\"   ‚úÖ {len(monitoring_data['timestamps'])} samples collected\")\n",
        "        print(f\"      First sample: {monitoring_data['timestamps'][0]}\")\n",
        "        print(f\"      Last sample: {monitoring_data['timestamps'][-1]}\")\n",
        "    else:\n",
        "        print(\"   ‚ÑπÔ∏è  No data collected yet\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚úÖ Health check complete!\")\n",
        "\n",
        "# Run health check\n",
        "comprehensive_health_check()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Common Issues and Solutions\n",
        "\n",
        "1. **SSH Connection Fails**\n",
        "   - Verify hostname/IP is correct\n",
        "   - Check VPN connection (if required)\n",
        "   - Verify SSH key permissions: `chmod 600 ~/.ssh/id_rsa`\n",
        "   - Test manual connection: `ssh username@hostname`\n",
        "\n",
        "2. **No GPU Metrics**\n",
        "   - Ensure nvidia-smi is installed on target system\n",
        "   - Check GPU drivers are loaded: `nvidia-smi` on remote host\n",
        "   - Verify user has permissions to access GPU\n",
        "\n",
        "3. **High Latency**\n",
        "   - Check network connection quality\n",
        "   - Verify VPN is not causing delays\n",
        "   - Consider monitoring locally if SSH latency is too high\n",
        "\n",
        "4. **Missing Dependencies**\n",
        "   - Install required packages: `pip install -r requirements.txt`\n",
        "   - For NVML: Ensure NVIDIA drivers are installed locally\n",
        "\n",
        "5. **Dashboard Not Updating**\n",
        "   - Ensure animation cell is running\n",
        "   - Check that metrics are being collected\n",
        "   - Verify matplotlib backend supports animation\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
